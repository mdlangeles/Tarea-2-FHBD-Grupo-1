{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ece8ed-3ddd-4e3b-b515-8344aa173fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs in /home/jovyan/.local/lib/python3.11/site-packages (2025.9.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /home/jovyan/.local/lib/python3.11/site-packages (from s3fs) (2.24.3)\n",
      "Requirement already satisfied: fsspec==2025.9.0 in /opt/conda/lib/python3.11/site-packages (from s3fs) (2025.9.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/jovyan/.local/lib/python3.11/site-packages (from s3fs) (3.13.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.40.46,>=1.40.37 in /home/jovyan/.local/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.40.45)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (2.8.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (6.7.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.22.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /opt/conda/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.15.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.40.46,>=1.40.37->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a0cd2-2c32-4f55-b30a-9b64a873dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlt\n",
    "!pip install minio\n",
    "!pip install --upgrade pyarrow\n",
    "!pip install --upgrade dlt\n",
    "!pip install --user \"dlt[s3]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ff980-a832-428a-8d66-dce5346cf734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import EndpointConnectionError, ClientError\n",
    "\n",
    "# Aquí define tus credenciales para revisar si conecta Jupyter con Minio. ¡Importante hacer esto para estar seguro de tus rutas!\n",
    "ENDPOINT = \"http://minio:9000\"\n",
    "ACCESS   = \"minioadmin\"\n",
    "SECRET   = \"minioadmin\"\n",
    "\n",
    "try:\n",
    "    s3 = boto3.client(\"s3\",\n",
    "                      endpoint_url=ENDPOINT,\n",
    "                      aws_access_key_id=ACCESS,\n",
    "                      aws_secret_access_key=SECRET)\n",
    "    response = s3.list_buckets()\n",
    "    response = s3.list_buckets()\n",
    "    print(\"Conectado correctamente a MinIO\")\n",
    "    print(\"Buckets encontrados:\", [b['Name'] for b in response.get('Buckets', [])])\n",
    "except EndpointConnectionError as e:\n",
    "    print(\"¡ERROR! No se pudo conectar al endpoint:\", e)\n",
    "except ClientError as e:\n",
    "    print(\"¡OJO! Error de cliente S3:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Otro error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7c251-c434-469b-9dc6-4d059a7fb994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://minio:9000\", \n",
    "    aws_access_key_id=\"minioadmin\",\n",
    "    aws_secret_access_key=\"minioadmin\"\n",
    ")\n",
    "\n",
    "bucket = \"lakehouse\"\n",
    "base_path = \"/data/StackOverflowData\"  # carpeta dentro DEL CONTENEDOR JUPYTER\n",
    "\n",
    "# Verificación por si la ruta no exite.\n",
    "if not os.path.exists(base_path):\n",
    "    raise FileNotFoundError(f\"No se encuentra la ruta {base_path}. Verifica el volumen en docker-compose.\")\n",
    "\n",
    "# Crear bronze por si no existe.\n",
    "prefix = \"bronze/\"\n",
    "try:\n",
    "    s3.list_objects_v2(Bucket=bucket, Prefix=prefix, MaxKeys=1)\n",
    "except ClientError as e:\n",
    "    print(\"Error al acceder al bucket:\", e)\n",
    "\n",
    "# Subir todo lo que sea .parquet! AVISO: Tarda su tiempo todo depende de los parquets seleccionados.\n",
    "EXCLUIR = {\"Comments2021.parquet\"} \n",
    "\n",
    "files = [f for f in os.listdir(base_path) if f.endswith(\".parquet\")]\n",
    "print(f\"Encontrados {len(files)} archivos parquet en {base_path}\")\n",
    "\n",
    "for i, file in enumerate(files, 1):\n",
    "    if file in EXCLUIR:\n",
    "        print(f\"[{i}/{len(files)}] Saltando {file} (se cargará con DLT)\")\n",
    "        continue  # pasa al siguiente archivo\n",
    "\n",
    "    src = os.path.join(base_path, file)\n",
    "    dest = f\"{prefix}{file}\"\n",
    "    print(f\"[{i}/{len(files)}] Subiendo {file} a MinIO ...\", end=\" \")\n",
    "    s3.upload_file(src, bucket, dest)\n",
    "    print(\"LISTO!\")\n",
    "\n",
    "print(\"Ingesta Bronze completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d91fbe-5371-4dc7-ac4b-dc59a38fe1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ingesta DLT (posts 2021)...\n",
      "Descargando: https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/comments/2021.parquet\n",
      "Arrow OK: 5536558 filas, 7 columnas\n"
     ]
    },
    {
     "ename": "PipelineStepFailed",
     "evalue": "Pipeline execution failed at `step=load` when processing package with `load_id=1760031133.0536427` with exception:\n\n<class 'PermissionError'>\nForbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/s3fs/core.py:114\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/aiobotocore/context.py:36\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m resolve_awaitable(hook())\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/aiobotocore/client.py:424\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    423\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (403) when calling the HeadObject operation: Forbidden",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:594\u001b[0m, in \u001b[0;36mPipeline.load\u001b[0;34m(self, destination, dataset_name, credentials, workers, raise_on_failed_jobs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m signals\u001b[38;5;241m.\u001b[39mdelayed_signals():\n\u001b[0;32m--> 594\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m info: LoadInfo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_step_info(load_step)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/common/runners/pool_runner.py:203\u001b[0m, in \u001b[0;36mrun_pool\u001b[0;34m(config, run_f)\u001b[0m\n\u001b[1;32m    202\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning pool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43m_run_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# for next run\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     signals\u001b[38;5;241m.\u001b[39mraise_if_signalled()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/common/runners/pool_runner.py:196\u001b[0m, in \u001b[0;36mrun_pool.<locals>._run_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(run_f, Runnable):\n\u001b[0;32m--> 196\u001b[0m     run_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/load/load.py:639\u001b[0m, in \u001b[0;36mLoad.run\u001b[0;34m(self, pool)\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_info_start_load_id(load_id)\n\u001b[0;32m--> 639\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_single_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TRunMetrics(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_storage\u001b[38;5;241m.\u001b[39mlist_normalized_packages()))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/load/load.py:528\u001b[0m, in \u001b[0;36mLoad.load_single_package\u001b[0;34m(self, load_id, schema)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (expected_update \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_storage\u001b[38;5;241m.\u001b[39mbegin_schema_update(load_id)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;66;03m# init job client\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m     applied_update \u001b[38;5;241m=\u001b[39m \u001b[43minit_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshould_truncate_table_before_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshould_load_data_to_staging_dataset\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjob_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWithStagingDataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropped_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncate_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncated_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;66;03m# init staging client\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/load/utils.py:117\u001b[0m, in \u001b[0;36minit_client\u001b[0;34m(job_client, schema, new_jobs, expected_update, truncate_filter, load_staging_filter, drop_tables, truncate_tables)\u001b[0m\n\u001b[1;32m    116\u001b[0m job_client\u001b[38;5;241m.\u001b[39mverify_schema(only_tables\u001b[38;5;241m=\u001b[39mtables_with_jobs \u001b[38;5;241m|\u001b[39m dlt_tables, new_jobs\u001b[38;5;241m=\u001b[39mnew_jobs)\n\u001b[0;32m--> 117\u001b[0m applied_update \u001b[38;5;241m=\u001b[39m \u001b[43m_init_dataset_and_update_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtables_with_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdlt_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncate_table_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_table_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# update the staging dataset if client supports this\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/load/utils.py:175\u001b[0m, in \u001b[0;36m_init_dataset_and_update_schema\u001b[0;34m(job_client, expected_update, update_tables, truncate_tables, staging_info, drop_tables)\u001b[0m\n\u001b[1;32m    170\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_client\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdestination_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement drop table.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Following tables \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrop_tables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will not be dropped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstaging_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         )\n\u001b[0;32m--> 175\u001b[0m \u001b[43mjob_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_client\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdestination_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will update schema to package schema\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstaging_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/destinations/impl/filesystem/filesystem.py:381\u001b[0m, in \u001b[0;36mFilesystemClient.initialize_storage\u001b[0;34m(self, truncate_tables)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# check if init file already exists\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_file_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    382\u001b[0m     current_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_storage_versions()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/s3fs/core.py:1093\u001b[0m, in \u001b[0;36mS3FileSystem._exists\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info(path, bucket, key, version_id\u001b[38;5;241m=\u001b[39mversion_id)\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/s3fs/core.py:1445\u001b[0m, in \u001b[0;36mS3FileSystem._info\u001b[0;34m(self, path, bucket, key, refresh, version_id)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1445\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[1;32m   1446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1447\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m   1448\u001b[0m         Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[1;32m   1449\u001b[0m         Key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m   1450\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mversion_id_kw(version_id),\n\u001b[1;32m   1451\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreq_kw,\n\u001b[1;32m   1452\u001b[0m     )\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m   1454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastModified\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastModified\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1462\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/s3fs/core.py:371\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[0;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m additional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_s3_method_kwargs(method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(\n\u001b[1;32m    372\u001b[0m     method, kwargs\u001b[38;5;241m=\u001b[39madditional_kwargs, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\n\u001b[1;32m    373\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/s3fs/core.py:146\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    145\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mPermissionError\u001b[0m: Forbidden",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 103\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProceso completado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 88\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m dlt\u001b[38;5;241m.\u001b[39mpipeline(\n\u001b[1;32m     80\u001b[0m     pipeline_name\u001b[38;5;241m=\u001b[39mPIPELINE_NAME,\n\u001b[1;32m     81\u001b[0m     destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,           \u001b[38;5;66;03m# primero a disco\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     dev_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIniciando ingesta DLT (posts 2021)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m load_info \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomments_2021_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader_file_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# fuerza parquet en filesystem\u001b[39;49;00m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDLT finalizado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(load_info)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:223\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    221\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:272\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    268\u001b[0m         ConfigSectionContext(\n\u001b[1;32m    269\u001b[0m             pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections, merge_style\u001b[38;5;241m=\u001b[39mmerge_func\n\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m     ):\n\u001b[0;32m--> 272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:737\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, table_format, schema_contract, refresh)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\n\u001b[1;32m    725\u001b[0m         data,\n\u001b[1;32m    726\u001b[0m         table_name\u001b[38;5;241m=\u001b[39mtable_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m         loader_file_format\u001b[38;5;241m=\u001b[39mloader_file_format,\n\u001b[1;32m    735\u001b[0m     )\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize()\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:223\u001b[0m, in \u001b[0;36mwith_runtime_trace.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace:\n\u001b[1;32m    221\u001b[0m         trace_step \u001b[38;5;241m=\u001b[39m start_trace_step(trace, cast(TPipelineStep, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_info\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:163\u001b[0m, in \u001b[0;36mwith_state_sync.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m should_extract_state \u001b[38;5;241m=\u001b[39m may_extract_state \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrestore_from_destination\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanaged_state(extract_state\u001b[38;5;241m=\u001b[39mshould_extract_state):\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:272\u001b[0m, in \u001b[0;36mwith_config_section.<locals>.decorator.<locals>._wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# add section context to the container to be used by all configuration without explicit sections resolution\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inject_section(\n\u001b[1;32m    268\u001b[0m         ConfigSectionContext(\n\u001b[1;32m    269\u001b[0m             pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, sections\u001b[38;5;241m=\u001b[39msections, merge_style\u001b[38;5;241m=\u001b[39mmerge_func\n\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m     ):\n\u001b[0;32m--> 272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dlt/pipeline/pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.load\u001b[0;34m(self, destination, dataset_name, credentials, workers, raise_on_failed_jobs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m l_ex:\n\u001b[1;32m    599\u001b[0m     step_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_step_info(load_step)\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineStepFailed(\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_step\u001b[38;5;241m.\u001b[39mcurrent_load_id, l_ex, step_info\n\u001b[1;32m    602\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01ml_ex\u001b[39;00m\n",
      "\u001b[0;31mPipelineStepFailed\u001b[0m: Pipeline execution failed at `step=load` when processing package with `load_id=1760031133.0536427` with exception:\n\n<class 'PermissionError'>\nForbidden"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import pyarrow.parquet as pq\n",
    "import dlt\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "URL = \"https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/comments/2021.parquet\"\n",
    "\n",
    "# MinIO (ajusta si corres fuera del contenedor)\n",
    "MINIO_ENDPOINT = os.environ.get(\"MINIO_ENDPOINT\", \"http://minio:9000\")\n",
    "MINIO_ACCESS   = os.environ.get(\"MINIO_ACCESS_KEY_ID\", \"minioadmin\")\n",
    "MINIO_SECRET   = os.environ.get(\"MINIO_SECRET_ACCESS_KEY\", \"minioadmin\")\n",
    "BUCKET         = os.environ.get(\"MINIO_BUCKET\", \"lakehouse\")\n",
    "PREFIX         = \"bronze\"   # destino lógico en Bronze\n",
    "\n",
    "# DLT: rutas y opciones\n",
    "PIPELINE_NAME  = \"bronze_ingest_dlt_comments2021\"\n",
    "DATASET_NAME   = \"comments_2021\"          # nombre lógico del dataset en filesystem (no afecta MinIO)\n",
    "PIPELINES_DIR  = \"/workspace/.dlt\"      # estado de dlt en disco\n",
    "\n",
    "\n",
    "@dlt.resource(name=\"comments_2021\", write_disposition=\"replace\")\n",
    "def comments_2021_arrow():\n",
    "    \"\"\"Descarga el Parquet remoto y lo entrega como Arrow Table (streaming seguro).\"\"\"\n",
    "    print(f\"Descargando: {URL}\")\n",
    "    with requests.get(URL, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".parquet\") as tmp:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "                if chunk:\n",
    "                    tmp.write(chunk)\n",
    "            tmp.flush()\n",
    "            table = pq.read_table(tmp.name)  # pyarrow.Table\n",
    "            print(f\"Arrow OK: {table.num_rows} filas, {table.num_columns} columnas\")\n",
    "            # DLT acepta pyarrow.Table; si tu versión no, descomenta el yield de dicts:\n",
    "            # for rec in table.to_pylist(): yield rec\n",
    "            yield table\n",
    "\n",
    "\n",
    "def ensure_bucket(s3, bucket: str):\n",
    "    try:\n",
    "        s3.head_bucket(Bucket=bucket)\n",
    "        print(f\"Bucket '{bucket}' existe.\")\n",
    "    except ClientError:\n",
    "        s3.create_bucket(Bucket=bucket)\n",
    "        print(f\"Bucket '{bucket}' creado.\")\n",
    "\n",
    "def upload_folder_to_minio(local_folder: str, bucket: str, prefix: str):\n",
    "    \"\"\"Sube todo el contenido generado por DLT (parquet/metadata) bajo bronze/posts/2021/\"\"\"\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=MINIO_ENDPOINT,\n",
    "        aws_access_key_id=MINIO_ACCESS,\n",
    "        aws_secret_access_key=MINIO_SECRET,\n",
    "    )\n",
    "    ensure_bucket(s3, bucket)\n",
    "\n",
    "\n",
    "    if not prefix.endswith(\"/\"):\n",
    "        prefix += \"/\"\n",
    "    s3.put_object(Bucket=bucket, Key=prefix)\n",
    "\n",
    "    uploaded = 0\n",
    "    for root, _, files in os.walk(local_folder):\n",
    "        for fname in files:\n",
    "            local_path = os.path.join(root, fname)\n",
    "            # clave relativa (conserva estructura de salida de DLT)\n",
    "            rel = os.path.relpath(local_path, local_folder).replace(\"\\\\\", \"/\")\n",
    "            s3_key = f\"{prefix}{rel}\"\n",
    "            print(f\"{local_path} → s3://{bucket}/{s3_key}\")\n",
    "            s3.upload_file(local_path, bucket, s3_key)\n",
    "            uploaded += 1\n",
    "    print(f\"Subidos {uploaded} archivos a s3://{bucket}/{prefix}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    pipeline = dlt.pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        destination=\"filesystem\",           # primero a disco\n",
    "        dataset_name=DATASET_NAME,\n",
    "        pipelines_dir=PIPELINES_DIR,\n",
    "        dev_mode=True,\n",
    "    )\n",
    "\n",
    "    print(\"Iniciando ingesta DLT (posts 2021)...\")\n",
    "    load_info = pipeline.run(\n",
    "        comments_2021_arrow(),\n",
    "        loader_file_format=\"parquet\",       # fuerza parquet en filesystem\n",
    "    )\n",
    "    print(\"DLT finalizado.\")\n",
    "    print(load_info)\n",
    "\n",
    "    # 2) Subir a MinIO → lakehouse/bronze/posts/2021/\n",
    "    output_dir = pipeline.dataset_path()    # carpeta donde DLT escribió parquet\n",
    "    print(f\"Output local DLT: {output_dir}\")\n",
    "    upload_folder_to_minio(output_dir, BUCKET, PREFIX)\n",
    "    print(\"Proceso completado.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6e9f7-194b-48d3-b0d1-844196f3e93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f186135-f7cb-42ac-b9a6-47c86e750e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
